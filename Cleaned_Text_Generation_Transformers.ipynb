{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwGrBiVqu1Jm"
   },
   "source": [
    "# Text Generation using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhyUWkTcYw0p"
   },
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113929,
     "status": "ok",
     "timestamp": 1749831591756,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "agBmyO40C8-u",
    "outputId": "51d7ba3d-55c1-4f20-bc24-06d3b19164b0"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb0qcQWeY0Pr"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13869,
     "status": "ok",
     "timestamp": 1749831477847,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "oYx1pSqCU1iC"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iFo1iEYY3EV"
   },
   "source": [
    "## Loading pre-trained Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "e5aea9dee3984879a58688c3480c83b2",
      "3c7249d3169c4c55b0b5da97c2908348",
      "f35050932c064dc8aff553a948e92800",
      "1ecc35280d7c4b3fa5e6b0f03c036f15",
      "4bdfb943246c492aab5ae803118ff13f",
      "7b79d2dd00534a16a1a0a25129705f65",
      "9baaf47137184e009ea5cfd71a6aed01",
      "c276e24ee0c1473b9d59c71adfd20f61",
      "5f7cfe310e9540f3a0d182de2e923de8",
      "a62107c44468408297719c1f99732253",
      "9d907ae57e9843e5b9116685fd4dcc97",
      "91ef4126ef194757aa2c3c47878d7302",
      "daa8f911ba8c41609a915665df37363c",
      "ac5e4c3bdfc34c5fab147d8ca47aded9",
      "da39f35530224619a6548d227d5406e5",
      "45119b9943e242009e4218a04fc1525f",
      "ce1971b7f1b4482e92b25d8569b1a90f",
      "489ba1ac0c594848a7168798b91c4297",
      "7d4b69ef4912445895768558cf007114",
      "3fe0c1e67aeb4cb4abbb588f8fc1fe62",
      "6b6bdcf573ad4335bd0a5dcd5d45e331",
      "e671ccb676c8418c98d42f70da582647",
      "0edb3b4759e74f8594770e93b0727b81",
      "3997b3207a75486899b108dcf1101296",
      "d8ed64a1eb7e4b82b79caf9438ba4ba5",
      "5db158ddbc2b40649b7cf4d071abc2c2",
      "3bf84c23245744ce8507e23f1d54f8e3",
      "8ec79b4cc0ec4e56be83ea60f6f3d115",
      "8f139fc5739243d6b593defec0c8167a",
      "cb5174f14ab649aea2e36111182509d7",
      "4888cc4e79e249eaa816705725689f11",
      "5d07e88a6dbc4f13beef0e93ce0dda78",
      "49274fc6fdd74da49825e0a68bbf188d",
      "2297f84d08a54f2e813bc8a8a5d3725c",
      "032f0ac456194c208dd370869b15720b",
      "4958e14f995b400697921a16ccc92825",
      "01db59359dd54788a25cb5e2238e8615",
      "e127b2f8879a4e1fab317de8ae416ead",
      "be5744e99c134253a66335cc10619485",
      "3bd8fcd2f7954394b15fe1e761b1b760",
      "01a860b6b2ee41c9a222191f4adbd74a",
      "b8ea60c8d87b4e86b9f65a58f9dba204",
      "4ea0fd8bab8943ee95affb1ec13f1b85",
      "0d3502db071a43e3ae70b22586d18f3e",
      "4eaec33a03484b97a1e344c9dae3d482",
      "2c931b89e91d4023adba710d17c4223e",
      "11f946a362dc462f98756f3c0d17e12b",
      "dfd8e2331e7e4711912aa574efddb93b",
      "7c0a8b5e1db74f1d86c0e096c337fcdb",
      "49d4b5a4b9c2467fb0e67672f9d92728",
      "d08c10cd134048b6ab3f99ee1ccaca6b",
      "52e83535c8d749109a5b1254f4de7351",
      "d2834f8ef8dc4588bcd8a25859d34294",
      "11fda34b6bba4b21a43ac3456a956574",
      "f9748cf2701a43208b77effa497de9f8",
      "1c4dc25d03504a578791af93abcb97a9",
      "3228ca3d471f4b26b44291aff09c5982",
      "32e1f2cd756e4620a0481ddaa97fe559",
      "2814c633b9d342019fe2ddf647a1f25c",
      "1d56e0854e7643e0ba09467edeae9178",
      "3943d8325e73410798789543d81c64a5",
      "b75a7e65e4814f79842b53584b8e4689",
      "a9a9cddf05de4729a4c5a44a83b45049",
      "555b8bad9f504dfdb757acbe2d395e09",
      "11fe97a8aeb94f4c8c60b3cdf4565b3d",
      "2e6695da868b45d692ce2ea69ae0f2c4"
     ]
    },
    "executionInfo": {
     "elapsed": 183174,
     "status": "ok",
     "timestamp": 1749831780771,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "kVaHWiTtKrYh",
    "outputId": "2ec524dc-da1d-4f75-ee99-f83bb30313a0"
   },
   "outputs": [],
   "source": [
    "# Model: GPT-Neo 1.3B (larger and stronger than GPT-2)\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set pad token if missing\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExTCKWcKZC1d"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1749831788983,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "UuvajJKyKvx0"
   },
   "outputs": [],
   "source": [
    "def generate_text_from_model(prompt, max_length=100, temperature=0.7, top_k=50, top_p=0.95):\n",
    "    # Tokenize prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    # Generate text with sampling\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and return\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPtBNsqpY_US"
   },
   "source": [
    "##Text Generation Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1749831794078,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "U4SNHv9xXF-7"
   },
   "outputs": [],
   "source": [
    "def text_generation():\n",
    "    print(\"Enter 'exit' to quit.\\n\")\n",
    "    while True:\n",
    "        prompt = input(\"Enter prompt: \")\n",
    "        if prompt.lower() == 'exit':\n",
    "            break\n",
    "        result = generate_text_from_model(prompt)\n",
    "        print(\"\\nGenerated Text:\\n\", result)\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 291242,
     "status": "error",
     "timestamp": 1749829703829,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "R_bp3otZbLVv",
    "outputId": "a426999e-eea0-45cd-e3d2-fc57ab7cf184"
   },
   "outputs": [],
   "source": [
    "text_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3808,
     "status": "ok",
     "timestamp": 1749831976162,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "I3wwUrH1HJEc",
    "outputId": "98347895-edf7-400e-934f-debce55b81aa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "error",
     "timestamp": 1749831104495,
     "user": {
      "displayName": "YASMEEN SHAJITHA S",
      "userId": "00697143220666384260"
     },
     "user_tz": -330
    },
    "id": "pmAC5GGRCgUo",
    "outputId": "366e2a44-7cb6-47f2-f3df-d60d791726d7"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Load your notebook (this assumes you're in Colab and editing this notebook)\n",
    "notebook_path = '/content/drive//Text_Generation_Transformers.ipynb'  # Change if needed\n",
    "cleaned_path = '/content/drive/MyDrive/INLAB INTERN/Cleaned_Text_Generation_Transformers.ipynb'\n",
    "\n",
    "# Read the notebook\n",
    "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Remove widget metadata if it exists\n",
    "if 'widgets' in nb['metadata']:\n",
    "    print(\"Removing invalid widget metadata...\")\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Optional: also clear cell outputs\n",
    "for cell in nb['cells']:\n",
    "    if 'outputs' in cell:\n",
    "        cell['outputs'] = []\n",
    "    if 'execution_count' in cell:\n",
    "        cell['execution_count'] = None\n",
    "\n",
    "# Save cleaned notebook\n",
    "with open(cleaned_path, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"âœ… Cleaned notebook saved as: {cleaned_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "12pmoxsdKHctErNF4oOYNUnmuTTYWlZFS",
     "timestamp": 1749831298073
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
